{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3-- Dynamic programming, alignment, sequences\n",
    "In this week we will turn our attention to a slightly more meaty computational topic-- sequence alignment. Our goal through the end of week three is to create a multiple alignment from a set of SARS-CoV-2 genomes that we might play with in coming weeks.\n",
    "\n",
    "As we talked about in lecture, the problem of sequence alignment arises because of the need for us to be comparing apples to apples between genomes. That is to say that we want to try to ensure that we are considering *homologous* traits, in this case basepairs of the genome, when we start to consider the evolutionary relationships among DNA sequences. \n",
    "\n",
    "Consider the number of ways in which two DNA sequences can be aligned one to another. It's easy enough to imagine that as these sequences themselves get longer, so too does the number of possible alignments. To figure out which alignment among all of these possibilities is the best will be a challenge, so we're gonna need a clever algorithm that allows us to compute stuff cheaply.\n",
    "\n",
    "Our solution comes from family of algorithms called Dynamic Programming. Dynamic programming exploits the fact that many problems can actually be decomposed into smaller subproblems, that when combined can solve a larger whole problem. This substructure solution comes from what we call _recursion_.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Fibonacci sequence\n",
    "The Fibonacci sequence was famously introduced by a 13th Century Italian mathematician of the same name to describe the growth of rabbit populations. The sequence of Fibonacci numbers goes like this:\n",
    "\n",
    "$F_0 = 0, F_1 = 1$ and $F_n = F_{n-1} + F_{n-2}$\n",
    "\n",
    "**Exercise 1:**\n",
    "In class, write a function to compute all of the Fibonacci series up to some defined $i$th term. Your function should take $i$, the last number in the series to calculate as input and return $F_i$\n",
    "\n",
    "## Recursive functions\n",
    "In mathematics recursive equations are those which are defined on the basis of previous terms of the same equation. For instance the Fibonacci series above is _recursive_ in that $F_n$ is calculated from $F_{n-1}$ and $F_{n-2}$. In computer programming the analog is a _recursive function_ that calls itself to achieve the desired output.\n",
    "\n",
    "As a very simple example check out the recursive function below `recFunc()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def recFunc(anInt):\n",
    "    print(anInt)\n",
    "    if anInt > 0:\n",
    "        anInt -= 1\n",
    "        recFunc(anInt)\n",
    "        \n",
    "recFunc(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here `recFunc()` is making calls to `recFunc()` from within it's own code until something happens! Can you follow the logic here? If you can the next thing to do is switch the order of the `if` block and the `print` statement. Now what's happening? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    " def recFunc(anInt):\n",
    "    if anInt > 0:\n",
    "        anInt -= 1\n",
    "        recFunc(anInt)\n",
    "    print(anInt)\n",
    "        \n",
    "recFunc(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:** In class, write a new Fibonacci function that outputs the $i$th term, but this time do it using a recursive function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F(i):\n",
    "    if i == 0:\n",
    "        return(0)\n",
    "    elif i == 1:\n",
    "        return(1)\n",
    "    else:\n",
    "        return(F(i-1) + F(i-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Programming version\n",
    "So let's say that we were writing a program that had to pull out lots of Fibonacci numbers over and over again, what would be a good way to do this efficient? Well what if we fill in a table to do this for us?\n",
    "\n",
    "**Exercise 3:** Write a new Fibonacci function, but this one will take as input $i$ the last term to be computed but will return a numpy array of Fibonacci numbers up to and including $F_i$. Can you think of a clever way to do this that uses the structure of the problem?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficiency comparison\n",
    "Let's see how long a naive implementation of the function which returns the list of Fibonacci numbers is versus a Dynamic programming implementation. To do this I'll use a jupyter built in trick called `%timeit` which will return the amount of time used by the computer to evaluate a block of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.27 ms ± 290 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "fs = np.zeros(20)\n",
    "for i in range(20):\n",
    "    fs[i] = F(i)\n",
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_dp(aInt):\n",
    "    res = np.ones(aInt)\n",
    "    if aInt > 1:\n",
    "        for i in range(2,aInt):\n",
    "            res[i] = res[i-1] + res[i-2]\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.53 µs ± 220 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "F_dp(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tower of Hanoi Game\n",
    "Okay let's look at a slightly more difficult dynamic programming problem-- solving for the minimum number of moves necessary to win the Tower of Hanoi game. Recall that the game consist of three rods (call them A, B, and C), onto which $n$ disks of increasing size sit. At the start of the game all $n$ disks are on the A rod. The objective is to move the $n$ disks to another rod (B or C). The rules are that \n",
    "1. Only 1 disk can be moved at a time\n",
    "2. Each move consists of moving the upper disk on a rod to the top of the pile on a different rod\n",
    "3. No larger disk may be placed on a smaller disk. \n",
    "\n",
    "Here's what an animation of the game looks like start from 6 disks\n",
    "\n",
    "<img src=imgs/Tower_of_Hanoi.gif>\n",
    "\n",
    "What's cool about this, seemingly hard problem is that we can break it up into the optimal move to do from any position, using a simple recursion. Here's what it looks like. Let's spend a bit of time analyzing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TowerOfHanoi(n , from_rod, to_rod, aux_rod): \n",
    "    if n == 1: \n",
    "        print(f\"Move disk 1 from rod {from_rod} to rod {to_rod}\") \n",
    "        return\n",
    "    TowerOfHanoi(n-1, from_rod, aux_rod, to_rod) \n",
    "    print(f\"Move disk {n} from rod {from_rod} to rod {to_rod}\")\n",
    "    TowerOfHanoi(n-1, aux_rod, to_rod, from_rod) \n",
    "    \n",
    "TowerOfHanoi(3 , \"A\", \"C\", \"B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** change the starting value of n (= the number of disks) to 2. Does this make sense? Now try a larger number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Alignment\n",
    "Now that we've spent a bit of time learning the context for dynamic programming, let's dig in to a more germane (and complex!) model-- that of global alignment of two sequences. The alignment method we will look at, the so-called Needleman-Wunsch algorithm, was developed by Saul B. Needleman and Christian D. Wunsch and published in 1970 in a [landmark publication](https://www.sciencedirect.com/science/article/abs/pii/0022283670900574?via%3Dihub). A key innovation here was that they represent a sequence alignment as a matrix, and fill in scores within that matrix using a dynamic programming approach, essentially breaking the large problem (global alignment) into a repeated series of smaller problems (should the next state be a gap, a match, or a mismatch). \n",
    "\n",
    "As we spent time thinking about this in class I won't belabor my description too much \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set sequences\n",
    "seq_1 = \"TAGACTA\"\n",
    "seq_2 = \"TACGGACGG\"\n",
    "\n",
    "# define penalties for alignment\n",
    "match = 4\n",
    "m_match = -3\n",
    "gap_penalty = -2\n",
    "\n",
    "subst_matrix = {\n",
    "'A': {'A': match,'C':m_match,'G':m_match,'T':m_match}, \n",
    "'C': {'A':m_match,'C': match,'G':m_match,'T':m_match}, \n",
    "'G': {'A':m_match,'C':m_match,'G': match,'T':m_match},\n",
    "'T': {'A':m_match,'C':m_match,'G':m_match,'T': match},\n",
    "}\n",
    "\n",
    "\n",
    "# this will store our dynamic programming matrix\n",
    "dp_matrix = np.ndarray(shape=(len(seq_1)+1,len(seq_2)+1), dtype=int)\n",
    "dp_matrix.fill(0)\n",
    "\n",
    "# storage for trace back matrix\n",
    "# 0 for up, 1 for diag, 2 for left\n",
    "back_ptr = np.ndarray(shape=(len(seq_1)+1,len(seq_2)+1), dtype=int)\n",
    "back_ptr.fill(-9)\n",
    "\n",
    "# fill the DP matrix\n",
    "for i in range(len(seq_1)+1):\n",
    "    for j in range(len(seq_2)+1):\n",
    "        if i==0 and j==0: continue # skip the first cell\n",
    "\n",
    "        char_1 = seq_1[i-1] # current character at seq 1\n",
    "        char_2 = seq_2[j-1] # current character at seq 2\n",
    "\n",
    "        scores = np.array([-999,-999,-999])\n",
    "        if( i>0 and j>0 ):  \n",
    "            # score diagonal\n",
    "            scores[1] = subst_matrix[char_1][char_2] + dp_matrix[i-1][j-1]\n",
    "            pass\n",
    "        if( i>0 ): \n",
    "            # score up: gap in sequence 2\n",
    "            scores[2] = gap_penalty + dp_matrix[i-1][j]\n",
    "            pass\n",
    "        if( j>0 ): \n",
    "            # score left: gap in sequence 1\n",
    "            scores[0] = gap_penalty + dp_matrix[i][j-1]\n",
    "            pass\n",
    "\n",
    "        # select the best previous cell\n",
    "        best = np.max(scores)\n",
    "        dp_matrix[i,j]=best\n",
    "        for k in range(3):\n",
    "            if scores[k] == best:\n",
    "                back_ptr[i,j] = k\n",
    "\n",
    "print(\"Dynamic programming matrix:\")\n",
    "print(dp_matrix)\n",
    "print(\"\\n traceback pointers:\")\n",
    "print(back_ptr)\n",
    "\n",
    "# read out the backtrace to get the best alignment\n",
    "aln_1 = \"\"\n",
    "aln_2 = \"\"\n",
    "i=len(seq_1)\n",
    "j=len(seq_2)\n",
    "\n",
    "while i>0 or j>0:\n",
    "    if back_ptr[i,j] == 0: # left\n",
    "        aln_1 += \"-\"\n",
    "        aln_2 += seq_2[j-1]\n",
    "        j -= 1\n",
    "    if back_ptr[i,j] == 1: # diag\n",
    "        aln_1 += seq_1[i-1]\n",
    "        aln_2 += seq_2[j-1]\n",
    "        i -= 1\n",
    "        j -= 1\n",
    "    if back_ptr[i,j] == 2: # up\n",
    "        aln_1 += seq_1[i-1]\n",
    "        aln_2 += \"-\"\n",
    "        i -= 1\n",
    "\n",
    "aln_1 = aln_1[::-1] # reverses the string\n",
    "aln_2 = aln_2[::-1]\n",
    "\n",
    "print(\"\\nAlignment:\")\n",
    "print(aln_1)\n",
    "print(aln_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** change the `gap_penalty` parameter above to equal 0. What is the reported alignment that you get out? Next return the `gap_penalty` to -2 but increase the mismatch penalty. Now what do you see?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the Needleman-Wunsch algorithm above performs _global_ alignment, i.e. it seeks the best alignment of all the bases in the two sequences. If we want to instead find the best alignment of subsequences between the two sequences we can use the related [Smith-Waterman algorithm](https://en.wikipedia.org/wiki/Smith%E2%80%93Waterman_algorithm). Recall from lecture that the only real differences here are that in Smith-Waterman scores in our DP matrix can't go below zero, and that the traceback starts at the *max* value cell and goes back until it encounters the first zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biopython \n",
    "Now that we know something about sequence alignment we are ready to move on to our case study for the week-- aligning SARS-CoV-2 genome data. To do this we will rely on the python package `biopython`.\n",
    "\n",
    "For anyone working with DNA or protein sequence information, `biopython` provides an extremely helpful set of tools. biopython gives the user the ability to programatically interact with biological sequence data and includes plugins to popular alignment and homology search algorithms such as BLAST or CLUSTAL, phylogenetic packages, and much more. We will barely scratch the surface in the kinds of things that one can accomplish, so if you are interested you can start reading the documentation [here](https://biopython.org/wiki/Documentation).\n",
    "\n",
    "\n",
    "## Working with sequences\n",
    "The first use case for us will be working with DNA sequences using biopython. biopython provides for us a `Seq` object, that contains at it's heart a string of biological sequence but that \"knows\" how to do certain tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sequences generally behave as strings, meaning that you can index them and iterate over them, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGTATCTTTGGT\n",
      "TCATAGAAACCA\n",
      "ACCAAAGATACT\n"
     ]
    }
   ],
   "source": [
    "from Bio.Seq import Seq\n",
    "my_seq = Seq(\"AGTATCTTTGGT\")\n",
    "print(my_seq)\n",
    "\n",
    "print(my_seq.complement())\n",
    "print(my_seq.reverse_complement())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside from containing strings `Seq` objects also have an alphabet that can be set so that the object is even a bit smarter. This can tell the object that it is dealing with DNA vs Proteins for instance or perhaps that it is dealing with an alphabet that might include ambiguities. The standard DNA and Protein alphabets can been established by an international chemical standards group called [IUPAC](https://iupac.org/). Here's the IUPAC DNA extended alphabet that allows for ambiguous positions\n",
    "\n",
    "<img src=imgs/iupac.png>\n",
    "\n",
    "we can set the alphabet associated with a Seq object directly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alphabet()\n",
      "IUPACUnambiguousDNA()\n"
     ]
    }
   ],
   "source": [
    "my_seq = Seq(\"AGTATCTTTGGT\")\n",
    "#check the alphabet of my_seq\n",
    "print(my_seq.alphabet) #returns a generic thing\n",
    "\n",
    "#set alphabet specifically\n",
    "from Bio.Alphabet import IUPAC\n",
    "my_seq = Seq(\"AGTATCTTTGGT\",IUPAC.unambiguous_dna)\n",
    "print(my_seq.alphabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sequences generally behave as strings, meaning that you can index them and iterate over them, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in my_seq:\n",
    "    print(c)\n",
    "    \n",
    "print(\"here is my_seq[0]: \",my_seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute GC percentage / 6-frame tx\n",
    "from Bio.SeqUtils import GC,six_frame_translations\n",
    "print(my_seq)\n",
    "print(\"percent GC \",GC(my_seq))\n",
    "print(\"\\n\")\n",
    "print(six_frame_translations(my_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are many other basic sequence utilities that biopython provides. you have to wade through the sequtils documentation a bit to find out everything that it can do out of the box.\n",
    "\n",
    "## Reading in sequences\n",
    "Perhaps the single most useful thing that biopython provides is basic utilities to read and write from common data formats such as fasta and fastq. These parsers really aid in our ability to quickly make headway on even sophisticated datasets. We will work with a set of orchid rRNA gene sequences that you can download [here](https://raw.githubusercontent.com/biopython/biopython/master/Doc/examples/ls_orchid.fasta) although I have also included the file in the github repo notebooks directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "for seq_record in SeqIO.parse(\"covid/data/gisaid_raw/gisaid_cov2020_sequences_15mar2020.fasta\", \"fasta\"):\n",
    "    print(\"id: \",seq_record.id,\"length: \",len(seq_record.seq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in large number of sequences as list of SeqRecords\n",
    "covid_records = list(SeqIO.parse(\"covid/data/gisaid_raw/gisaid_cov2020_sequences_15mar2020.fasta\", \"fasta\"))\n",
    "# write first 20 into small file\n",
    "SeqIO.write(covid_records[0:20], \"covid/data/gisaid_raw/covid_small.fasta\", \"fasta\")\n",
    "# read small file\n",
    "covid_records = list(SeqIO.parse(\"covid/data/gisaid_raw/covid_small.fasta\", \"fasta\"))\n",
    "print(len(covid_records))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SeqIO.parse()` actually returns a specific python object called an iterator that can be operated on in a different way, asking it to give you the next object over and over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a slightly different way to deal with the iterator that SeqIO.parse returns    \n",
    "record_iterator = SeqIO.parse(\"ls_orchid.fasta\", \"fasta\")\n",
    "first_record = next(record_iterator)\n",
    "print(first_record.id)\n",
    "print(first_record.description)\n",
    "\n",
    "second_record = next(record_iterator)\n",
    "print(second_record.id)\n",
    "print(second_record.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting sequences straight from Genbank\n",
    "biopython has code that allows us to download sequences directly from genbank and suck them up in to memory for doing stuff. this is particularly useful for snatching _reference sequences_, the an official representation of a sequence that is often well annotated. We will use this interface to grab a reference genome for SARS-CoV-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "# need this fake email for the service to work\n",
    "Entrez.email = \"fake_email@thanks.com\"\n",
    "with Entrez.efetch(db=\"nucleotide\", rettype=\"fasta\", retmode=\"text\", id=\"NC_045512.2\") as handle:\n",
    "    seq_record = SeqIO.read(handle, \"fasta\")\n",
    "print(seq_record.id, seq_record.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SeqRecords\n",
    "the workhorse here is a class called a `SeqRecord` that biopython provides to us. we can get a bunch of information here just be asking the object to print itself. these are smart. full documentation on these [here](https://biopython.org/wiki/SeqRecord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seq_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can get a bit more information if we retreive files in the so-called genbank format, in particular we will get annotation features associated with the sequence, if they exist in the genbank entry. The genbank page for this entry can be found [here](https://www.ncbi.nlm.nih.gov/nuccore/NC_045512.2), we can look it over in class together to see all the neat information that they include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "Entrez.email = \"A.N.Other@example.com\"\n",
    "with Entrez.efetch(db=\"nucleotide\", rettype=\"gb\", retmode=\"text\", id=\"NC_045512.2\") as handle:\n",
    "    seq_record = SeqIO.read(handle, \"gb\")\n",
    "print(seq_record.id, seq_record.description)\n",
    "#gene_list = [ x  for x in seq_record.features if x.type == 'CDS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perhaps the biggest thing we get with the genbank file format is _annotations_, that is features of the genome that are represented and stored as so-called SeqFeatures. I can get these by looking at the `.features` attribute associated with my sequence records.\n",
    "\n",
    "Let's look at the first four features entry from our file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,x in enumerate(seq_record.features):\n",
    "    if i < 4:\n",
    "        print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What genes are in here? Grabbing feature sequences\n",
    "okay lets get a list of gene names from our features. I've been reading about the spike protein for weeks-- should we look at it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of genes\n",
    "gene_list = [ x  for x in seq_record.features if x.type == 'CDS']\n",
    "for i,x in enumerate(gene_list):\n",
    "    print(x.qualifiers['gene'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "okay that S protein is the one. Let's grab it out of our sequence then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the spike protein\n",
    "spike = gene_list[2].extract(seq_record)\n",
    "#print it's sequence\n",
    "print(spike.seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can even turn this into a protein translation with ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spike.seq.translate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note that this starts with an 'M' and ends with a stop codon '*' just like we would expect. looks awesome!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence files as dicts\n",
    "If you have a large number of sequences in a file, it's usually best not to read them all in to memory at once. biopython has you covered here functions that will open up a sequence file as sa dictionary that you can query by key\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_dict = SeqIO.index(\"covid/data/gisaid_raw/covid_small.fasta\", \"fasta\")\n",
    "print(list(covid_dict.keys())[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_record = orchid_dict['hCoV-19/Wuhan/WIV07/2019|EPI_ISL_402130|2019-12-30']\n",
    "print(seq_record.description)\n",
    "print(seq_record.seq[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting between file formats\n",
    "\n",
    "Again biopython has you covered for basic conversions between file formats. For instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "count = SeqIO.convert(\"ls_orchid.fasta\", \"fasta\", \"my_example.pir\", \"pir\")\n",
    "print(\"Converted %i records\" % count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing multiple sequence alignment\n",
    "not only can biopython read and write multiple sequence alignments (MSAs) and cleanly represent them in memory, but biopython can even help you create MSAs. \n",
    "biopython can work as glue that binds together familiar bioinformatics programs, allowing us to pass information from memory to programs and then back. This depends on having \"helper\" programs installed that will do the heavy lifting, for instance an alignment program. When we started off this lecture we installed the aligner MUSCLE using conda. We will use the interface to MUSCLE to demostrate this functionality.\n",
    "\n",
    "In particular we will do an alignment of the sequences in that orchid fasta file we have been playing with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from Bio.Align.Applications import MafftCommandline\n",
    "mafft_cline = MafftCommandline(\"mafft\", input=\"covid/data/gisaid_raw/covid_small.fasta\")\n",
    "muscle_exe = \"/Users/adk/miniconda3/bin/mafft\"\n",
    "assert os.path.isfile(muscle_exe), \"mafft executable missing\"\n",
    "stdout, stderr = mafft_cline()\n",
    "with open(\"aligned.fasta\", \"w\") as handle:\n",
    "    handle.write(stdout)\n",
    "# this will take a while\n",
    "# can print stderr if you want to see what happened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SingleLetterAlphabet() alignment with 20 rows and 29899 columns\n",
      "--------------ccttcccaggtaacaaaccaaccaactttc...--- hCoV-19/Wuhan/WIV06/2019|EPI_ISL_402129|2019-12-30\n",
      "-------------accttcccaggtaacaaaccaaccaactttc...--- hCoV-19/Wuhan/WIV07/2019|EPI_ISL_402130|2019-12-30\n",
      "-----------ataccttcccaggtaacaaaccaaccaactttc...--- hCoV-19/Guangdong/20SF012/2020|EPI_ISL_403932|2020-01-14\n",
      "-----------ataccttcccaggtaacaaaccaaccaactttc...--- hCoV-19/Guangdong/20SF013/2020|EPI_ISL_403933|2020-01-15\n",
      "-----------ataccttcccaggtaacaaaccaaccaactttc...--- hCoV-19/Guangdong/20SF014/2020|EPI_ISL_403934|2020-01-15\n",
      "-----------ataccttcccaggtaacaaaccaaccaactttc...--- hCoV-19/Guangdong/20SF025/2020|EPI_ISL_403935|2020-01-15\n",
      "-----------ataccttcccaggtaacaaaccaaccaactttc...--- hCoV-19/Guangdong/20SF028/2020|EPI_ISL_403936|2020-01-17\n",
      "-----------ataccttcccaggtaacaaaccaaccaactttc...--- hCoV-19/Guangdong/20SF040/2020|EPI_ISL_403937|2020-01-18\n",
      "attaaaggtttataccttcccaggtaacaaaccaaccaactttc...aaa hCoV-19/Wuhan/IPBCAMS-WH-03/2019|EPI_ISL_403930|2019-12-30\n",
      "-----------ataccttcccaggtaacaaaccaaccaactttc...--- hCoV-19/Wuhan/HBCDC-HB-01/2019|EPI_ISL_402132|2019-12-30\n",
      "-------------------ccaggtaacaagccaaccaactttc...--- hCoV-19/Zhejiang/WZ-01/2020|EPI_ISL_404227|2020-01-16\n",
      "--------------------------acaaaccaaccaactttc...--- hCoV-19/Zhejiang/WZ-02/2020|EPI_ISL_404228|2020-01-17\n",
      "attaaaggtttataccttcccaggtaacaaaccaaccaactttc...--- hCoV-19/USA/WA1/2020|EPI_ISL_404895|2020-01-19\n",
      "nnnnnnnnnnnntaccttcccaggtaacaaaccaaccaactttc...--- hCoV-19/Finland/1/2020|EPI_ISL_407079|2020-01-29\n",
      "attaaaggtttataccttcccaggtaacaaaccaaccaactttc...--- hCoV-19/Shenzhen/HKU-SZ-005/2020|EPI_ISL_405839|2020-01-11\n",
      "--------------------------------caaccaactttc...--- hCoV-19/Shenzhen/HKU-SZ-002/2020|EPI_ISL_406030|2020-01-10\n",
      "attaaaggtttataccttcccaggtaacaaaccaaccaactttc...--- hCoV-19/USA/IL1/2020|EPI_ISL_404253|2020-01-21\n",
      "attaaaggtttataccttcccaggtaacaaaccaaccaactttc...--- hCoV-19/USA/CA1/2020|EPI_ISL_406034|2020-01-23\n",
      "attaaaggtttataccttcccaggtaacaaaccaaccaactttc...--- hCoV-19/USA/CA2/2020|EPI_ISL_406036|2020-01-22\n",
      "attaaaggtttataccttcccaggtaacaaaccaaccaactttc...--- hCoV-19/USA/AZ1/2020|EPI_ISL_406223|2020-01-22\n"
     ]
    }
   ],
   "source": [
    "#now suck back in the file\n",
    "from Bio import AlignIO\n",
    "\n",
    "cov_align = AlignIO.read(\"aligned.fasta\",\"fasta\")\n",
    "print(cov_align)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these alignment objects behave as you would expect. for instance we can slice them just as we would numpy arrays to get subsets of the aligned sequences, windows of the alignment, or both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count number of differences\n",
    "let's write a function to count the number of differences between the two sequences in our alignments. we will do this by using a simple loop and asking if the characters are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage different = 0.0006020469596628537\n"
     ]
    }
   ],
   "source": [
    "def count_diffs(align, seq1, seq2):\n",
    "    diffs = 0\n",
    "    for i in range(len(align[0].seq)):\n",
    "        if align[seq1, i] != align[seq2, i]:\n",
    "            print(f'different at position {i} -> {align[:, seq1]}')\n",
    "            diffs += 1\n",
    "            \n",
    "    print(f'number of diffs = {diffs}')\n",
    "    print(f'percentage different = {diffs / i}')\n",
    "\n",
    "count_diffs(cov_align,0,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** rewrite the above function to only count differences between sequences that do not include alignment gaps (i.e. \"-\"). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add reference sequence and realign\n",
    "So the alignment above is great, but we don't have any of our annotations from the Genbank file on there. Let's now add the Genbank reference sequence into our alignment and realign the whole thing. The steps here will be to:\n",
    "1. add the reference to the alignment object\n",
    "2. write this out to a file\n",
    "3. rerun the alignment step from above with the new input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seq_record' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9fdaa183064f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mEntrez\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nucleotide\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrettype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"NC_045512.2\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mrefseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeqIO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"downloaded\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_record\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seq_record' is not defined"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "\n",
    "# get the reference seq\n",
    "# need this fake email for the service to work\n",
    "Entrez.email = \"fake_email@thanks.com\"\n",
    "with Entrez.efetch(db=\"nucleotide\", rettype=\"gb\", retmode=\"text\", id=\"NC_045512.2\") as handle:\n",
    "    refseq = SeqIO.read(handle, \"gb\")\n",
    "print(\"downloaded\", refseq.id, seq_record.description)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then make a list from cov_align and add refseq; write to temp.fasta\n",
    "longer_list = [x for x in cov_align]\n",
    "longer_list.append(refseq)\n",
    "SeqIO.write(longer_list, \"temp.fasta\", \"fasta\")\n",
    "\n",
    "#now run alignment\n",
    "mafft_cline = MafftCommandline(\"mafft\", input=\"temp.fasta\")\n",
    "assert os.path.isfile(muscle_exe), \"mafft executable missing\"\n",
    "stdout, stderr = mafft_cline()\n",
    "with open(\"temp.aligned.fasta\", \"w\") as handle:\n",
    "    handle.write(stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SingleLetterAlphabet() alignment with 21 rows and 29903 columns\n",
      "--------------ccttcccaggtaacaaaccaaccaactttc...--- hCoV-19/Wuhan/WIV06/2019|EPI_ISL_402129|2019-12-30\n",
      "-------------accttcccaggtaacaaaccaaccaactttc...--- hCoV-19/Wuhan/WIV07/2019|EPI_ISL_402130|2019-12-30\n",
      "-----------ataccttcccaggtaacaaaccaaccaactttc...--- hCoV-19/Guangdong/20SF012/2020|EPI_ISL_403932|2020-01-14\n",
      "-----------ataccttcccaggtaacaaaccaaccaactttc...--- hCoV-19/Guangdong/20SF013/2020|EPI_ISL_403933|2020-01-15\n",
      "-----------ataccttcccaggtaacaaaccaaccaactttc...--- hCoV-19/Guangdong/20SF014/2020|EPI_ISL_403934|2020-01-15\n",
      "-----------ataccttcccaggtaacaaaccaaccaactttc...--- hCoV-19/Guangdong/20SF025/2020|EPI_ISL_403935|2020-01-15\n",
      "-----------ataccttcccaggtaacaaaccaaccaactttc...--- hCoV-19/Guangdong/20SF028/2020|EPI_ISL_403936|2020-01-17\n",
      "-----------ataccttcccaggtaacaaaccaaccaactttc...--- hCoV-19/Guangdong/20SF040/2020|EPI_ISL_403937|2020-01-18\n",
      "attaaaggtttataccttcccaggtaacaaaccaaccaactttc...--- hCoV-19/Wuhan/IPBCAMS-WH-03/2019|EPI_ISL_403930|2019-12-30\n",
      "-----------ataccttcccaggtaacaaaccaaccaactttc...--- hCoV-19/Wuhan/HBCDC-HB-01/2019|EPI_ISL_402132|2019-12-30\n",
      "-------------------ccaggtaacaagccaaccaactttc...--- hCoV-19/Zhejiang/WZ-01/2020|EPI_ISL_404227|2020-01-16\n",
      "--------------------------acaaaccaaccaactttc...--- hCoV-19/Zhejiang/WZ-02/2020|EPI_ISL_404228|2020-01-17\n",
      "attaaaggtttataccttcccaggtaacaaaccaaccaactttc...--- hCoV-19/USA/WA1/2020|EPI_ISL_404895|2020-01-19\n",
      "nnnnnnnnnnnntaccttcccaggtaacaaaccaaccaactttc...--- hCoV-19/Finland/1/2020|EPI_ISL_407079|2020-01-29\n",
      "attaaaggtttataccttcccaggtaacaaaccaaccaactttc...--- hCoV-19/Shenzhen/HKU-SZ-005/2020|EPI_ISL_405839|2020-01-11\n",
      "--------------------------------caaccaactttc...--- hCoV-19/Shenzhen/HKU-SZ-002/2020|EPI_ISL_406030|2020-01-10\n",
      "attaaaggtttataccttcccaggtaacaaaccaaccaactttc...--- hCoV-19/USA/IL1/2020|EPI_ISL_404253|2020-01-21\n",
      "attaaaggtttataccttcccaggtaacaaaccaaccaactttc...--- hCoV-19/USA/CA1/2020|EPI_ISL_406034|2020-01-23\n",
      "...\n",
      "attaaaggtttataccttcccaggtaacaaaccaaccaactttc...aaa NC_045512.2\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "#import and look at it\n",
    "new_align = AlignIO.read(\"temp.aligned.fasta\",\"fasta\")\n",
    "print(new_align)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see that last sequence name? that's our reference genome! let's see if there are any gaps inserted into the reference. this is important because it will throw off the locations of our annotations (e.g. genes) that we got with our reference sequence. Do do this I'll just use the built in biopython function `count()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(new_align[-1].seq.count(\"-\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so we are actually good to go here-- things line up well to the reference. Next let's try to apply our annotation to the alignment and pull out specific regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 2 \n",
      " type: CDS\n",
      "location: [21562:25384](+)\n",
      "qualifiers:\n",
      "    Key: codon_start, Value: ['1']\n",
      "    Key: db_xref, Value: ['GeneID:43740568']\n",
      "    Key: gene, Value: ['S']\n",
      "    Key: gene_synonym, Value: ['spike glycoprotein']\n",
      "    Key: locus_tag, Value: ['GU280_gp02']\n",
      "    Key: note, Value: ['structural protein; spike protein']\n",
      "    Key: product, Value: ['surface glycoprotein']\n",
      "    Key: protein_id, Value: ['YP_009724390.1']\n",
      "    Key: translation, Value: ['MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFSNVTWFHAIHVSGTNGTKRFDNPVLPFNDGVYFASTEKSNIIRGWIFGTTLDSKTQSLLIVNNATNVVIKVCEFQFCNDPFLGVYYHKNNKSWMESEFRVYSSANNCTFEYVSQPFLMDLEGKQGNFKNLREFVFKNIDGYFKIYSKHTPINLVRDLPQGFSALEPLVDLPIGINITRFQTLLALHRSYLTPGDSSSGWTAGAAAYYVGYLQPRTFLLKYNENGTITDAVDCALDPLSETKCTLKSFTVEKGIYQTSNFRVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNFNFNGLTGTGVLTESNKKFLPFQQFGRDIADTTDAVRDPQTLEILDITPCSFGGVSVITPGTNTSNQVAVLYQDVNCTEVPVAIHADQLTPTWRVYSTGSNVFQTRAGCLIGAEHVNNSYECDIPIGAGICASYQTQTNSPRRARSVASQSIIAYTMSLGAENSVAYSNNSIAIPTNFTISVTTEILPVSMTKTSVDCTMYICGDSTECSNLLLQYGSFCTQLNRALTGIAVEQDKNTQEVFAQVKQIYKTPPIKDFGGFNFSQILPDPSKPSKRSFIEDLLFNKVTLADAGFIKQYGDCLGDIAARDLICAQKFNGLTVLPPLLTDEMIAQYTSALLAGTITSGWTFGAGAALQIPFAMQMAYRFNGIGVTQNVLYENQKLIANQFNSAIGKIQDSLSSTASALGKLQDVVNQNAQALNTLVKQLSSNFGAISSVLNDILSRLDKVEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQSAPHGVVFLHVTYVPAQEKNFTTAPAICHDGKAHFPREGVFVSNGTHWFVTQRNFYEPQIITTDNTFVSGNCDVVIGIVNNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQYIKWPWYIWLGFIAGLIAIVMVTIMLCCMTSCCSCLKGCCSCGSCCKFDEDDSEPVLKGVKLHYT']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find S gene index\n",
    "gene_list = [ x  for x in refseq.features if x.type == 'CDS']\n",
    "for i,x in enumerate(gene_list):\n",
    "    if x.qualifiers['gene'] == ['S']:\n",
    "        print(\"index\",i,\"\\n\",x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_align = new_align[:,gene_list[2].location.start.position:gene_list[2].location.end.position]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_diffs2(align, seq1, seq2):\n",
    "    diffs = 0\n",
    "    for i in range(len(align[0].seq)):\n",
    "        if align[seq1, i] != align[seq2, i] and align[seq1, i] != '-' \\\n",
    "            and align[seq2, i] != \"-\":\n",
    "            diffs += 1\n",
    "    return(diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10b2e9b70>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "n = len(spike_align)\n",
    "dist_mat = np.zeros((n,n))\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        dist_mat[i,j] = count_diffs2(spike_align,i,j)\n",
    "\n",
    "plt.imshow(dist_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10b6c46a0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from Bio.Align import MultipleSeqAlignment\n",
    "align = MultipleSeqAlignment([])\n",
    "for i in range(13):\n",
    "    align.append(spike_align[i])\n",
    "for i in range(14,21):\n",
    "    align.append(spike_align[i])\n",
    "\n",
    "#print(align)\n",
    "n = len(align)\n",
    "dist_mat = np.zeros((n,n))\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        dist_mat[i,j] = count_diffs2(align,i,j)\n",
    "\n",
    "plt.imshow(dist_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get summary info\n",
    "from Bio.Align import AlignInfo\n",
    "summary_align = AlignInfo.SummaryInfo(cov_align)\n",
    "consensus = summary_align.dumb_consensus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position specific weight matrix for bp 100-110\n",
    "summary_align = AlignInfo.SummaryInfo(orchid[:,0:10])\n",
    "consensus = summary_align.dumb_consensus()\n",
    "print(\"consensus sequence: \",consensus)\n",
    "my_pssm = summary_align.pos_specific_score_matrix(consensus, chars_to_ignore = ['N'])\n",
    "print(my_pssm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
